MapReduce用来解决大规模数据分布式计算问题，既是一个编程模型，也是一个计算框架。开发人员基于MapReduce编程模型开发，然后通过MapReduce计算框架把程序分发到Hadoop集群中运行。

整个过程大致如下：

- HDFS分布式存储已经存在，比如把应用程序的jar包放在某个地方。DataNode和DataName也存在了，是主从或1对多关系，DataName还可以借助Zookeeper管理。
- MapReduce的程序入口被放在了一个大数据应用程序服务器，在这个大数据应用程序服务器内有一个配置文件，执行Map和Reduce类、输入输出文件，这里的应用程序启动起来，就有了大数据应用程序进程，这个进程里的JobClient从HDFS拿来JAR包，以作业的方式交给下一步。
- 下一步就到了JobTracker的服务器，开一个JobTracker进程，它在Hadoop集群中时常驻进程，是唯一的，管理着整个作业生命周期的任务调度和监控，具体会把每一个作业交给JobTracker的JobScheduler来做，每个作业的JobScheduler会维护着一个JobInProcess的树型结构，这个树的节点就是TaskInProcess,代表着每个TaskTracker进程
- TaskTracker进程和DataNode进程通常在同一台服务器上。JobTracker进程和TaskTracker进程是主从关系，或者说1对多关系，两者会定时通信。TaskTracker进程根据服务器名字，匹配与TaskTracker进程在同一台服务器上的DataNode给Map函数。TaskTracker进程启动Map和Reduce进程。DataNode进程把jar文件和Bock区块数据交给map函数，具体是如果在当前的DataNode上没有jar包就会到HDFS中去下载，具体包括了jar包路径、输入数据文件路径、要处理数据在HDFS中的起始位置和偏移量、数据块在多个DataNode上的备份，map会把计算结果写入到本地(Spark不会写入本地)。然后就是shuffle过程，shuffle的过程就是把不同服务器上的数据合并在一起交给reduce，会根据key的哈希值对reduce任务数量取模，相同的key会有相同的任务ID(如果key对应的任务id上的数据比较大，这叫数据倾斜)，启动shuffle的时机是在map快要结束的时候，内部会调用partition接口，对Map产生的每个<key, value>分区选择，HTTP发送给reduce进程， reduce进程接受<key, value>集合排序并合并，再交给reduce，redue把结果输出到HDFS上保存。

总之，MapReduce把计算分发到了不同的DataNode之上。