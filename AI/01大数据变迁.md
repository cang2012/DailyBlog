


在互联网初期，分析用户需求和业务场景进行软件设计和开发，把现实世界的业务数字化，通过软件和网络进行业务和数据处理。等着用户输入，执行编写好的逻辑。

当各个层面被软件重塑后，效率也提高了不少，这时候软件、云、计算也成了基础设施，如何洞悉呢？可以预测用户的期望，在你还没有想好的情况下，主动提供建议和选项。这需要海量数据，也需要机器学习。

早期，通过提升单机性能，使用更好的服务器来提高效率。

2004年，Google三篇论文，分布式文件GFS，分布式计算框架MapReduce,NoSQL数据库BigTable，用来解决网页抓取、索引构建需要大量的存储和计算问题。把这三个方面做好了，Google只需要把普通的服务器组织到一起就能形成合力。同时，Lucene开源项目的创始人Doug Cutting正在开发开源搜索引擎Nutch，他根据Google的论文，实现了类似MapReduce和GFS的功能。

2006年，Doug Cutting将大数据相关功能从Nutch分离出来，推出了Hadoop，包含了分布式文件系统HDFS、大数据计算引擎MarReduce。

Yahoo开始使用，还发明了Pig脚本语言，用来描述对大数据集上进行的操作，编译生成MapReduce程序，在Hadoop上运行，但是需要学习脚本语法。Facebook发明了Hive，支持SQL语法进行大数据计算，把SQL语句转换成MapReduce程序。这样，大数据分析师和工程师可以无门槛地使用大数据了。

2007年，百度、阿里巴巴开始使用大数据技术。

2011年，Facebook大数据平台上的90%来源于Hive。

2011年左右也诞生了很多NoSQL数据库，用来存储访问大规模海量数据的存储。涌现出HBase, Cassandra,HBase是从Hadoop中分离出来的基于HDFS的NoSQL数据库。

在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度由MapReduce完成，这样MapReduce非常臃肿。

2012年，Yarn成为独立项目开始运营，成为大数据平台上最主流的资源调度系统。

2012年，UC伯克利的AMP实验室(Algorithms, Machine, People)开发出Spark。AMP实验室的马铁博士发现MapReduce的性能非常差，主要表现在两方面：MapReduce使用磁盘作为介质，而在2012年的时候内存已经突破容量和成本限制，成为数据运行过程中的主要介质；机器学习需要进行多次的迭代，而MapReduce每次执行Map和Reduce都需要重启一次作业，带来无谓消耗。

众多Hadoop周边产品出现。Sqoop把关系数据库的数据导入到Hadoop平台；Flume对大规模分布式日志进行收集、聚合和传输；MapReduce的工作流引擎Oozie。

MapReduce、Spark被称为大数据离线计算、批处理计算，通常是以天为单位产生的数据进行一次运算，计算呢需要花费几十分钟甚至更长时间，拿到的数据是历史数据。

还有需要实时计算的，比如对监控摄像头进行人脸识别，这些计算叫大数据流计算。相应地有Storm, Flink, Spark Streaming等流量计算框架。流式计算也被称为大数据实时计算。

通常情况下，批处理历史数据，对新增的数据采用流式计算。而Flink既可以批处理计算也可以流式计算。

2013年，BAT纷纷使用大数据技术，2013年被称为大数据元年。

2016年，Google的AlphaGo横空出世。

以上的大数据处理引擎或者大数据框架为进行大数据分析、数据挖掘、机器学习提供了前提。数据分析有Hive, Spark SQL等SQL引擎。数据挖掘与机器学习有专门的机器学习框架TensorFlow, Mahout,MLlib,其中内置了机器学习和数据挖掘算法。

到这里，大数据平台的概貌就出来了。

> 最底层的是大数据存储HDFS；再上面一层是以HBase, Cassandra为代表的NoSQL、以MapReduce和Spark为代表的大数据批处理计算、以Storm, Flink, Spark Streaming为代表的大数据流处理。再上面一层是以Hive, Spark SQL为代表的SQL查询，以TensorFlow, Mahout, MLlib为代表的大数据挖掘与机器学习。

> 这个时代最聪明的人，永远是在历史前进的逻辑中前进，在时代发展的潮流中站在潮流之上。历史由天才开启，由普通人创造。


Google做了什么呢？存储全世界网页，存储到GFS上，构建搜索引擎，对所有文件中的单词进行词频统计，根据PageRank算法给网页排名，需要很多计算，所以才有了MapReduce。

Google之前最著名的是Yahoo的搜索引擎。

Doug Cutting根据Google的论文做了Hadoop, Yahoo把Doug Cutting挖了过去专职做Hadoop，Doug Cutting不喜欢Yahoo的内部斗争去了Hadoop的商业公司Cloudera,而Yahoo投资了Cloudera的竞争对手HortonWorks，真所谓不是朋友就是对手。

当日志、应用采集数据、数据库放到一起成为了企业的数据仓库或者数据湖，而Hive的出现意味着可以在Hadoop上使用SQL进行实时统计与分析，用更低廉的价格拥有了更多的数据存储和计算能力。


有了数据仓库或者数据库，那就需要对数据进行挖掘，挖掘出价值。数据关联，标签，人际关系。还可以把全部事实数据都收集起来，统计规律，预测正在发生的事情。

人工智能只是根据大数据计算出来的统计规律，即使表现得再智能，人工智能本身不知道这样做的意义，也不能定义概念，而意义和定义概念是人类独有的能力。

大数据在医疗。医疗领域有海量数据，有万亿级市场规模。医学影像智能识别辅助医生。病历大数据智能诊断，针对海量专家临床病历，使用病历智能处理引擎得到病历知识库，结合用药知识库、科技文献知识库、循证医学数据库形成一个大的数据库，然后根据病人的病情，以知识库为基础，使用知识匹配搜索引擎给出建议服务和方案供医生选择。

大数据在教育。根据学生能力和学习节奏，及时调整大纲和学习进度。AI外语老师。智能解题。

大数据在社交。舆情监控与分析。

大数据在金融领域。大数据风控。

大数据在新零售。生产、物流、购物、使用大数据进行分析和预判，实现精准生产、零库存、全兴购物体验。

大数据在智能交通。
