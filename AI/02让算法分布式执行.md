当产生的数据数量级足够高，比如以PB为单位，即10<sup>15</sup>这个数量级，而带宽通常在几百MB，内存几十GB，磁盘在TB单台服务器无法胜任。

在处理网站并发请求，有了分布式，当用户请求过来，由于用户请求间是相互独立的，就根据不同用户不同业务场景把请求分发到不同的服务器上，这是实时请求的分发，里面用到了负载均衡，分布式缓存，分布式数据库，分布式服务，这就好比来了不同的来宾用不同的人招待。

整个分布式架构产生了海量的数据，分治思想可以把数据切片，但是这里还有一个问题，一个单体应用程序能处理的数据量总是有限的，我们需要很多个单体应用程序同时对切片数据进行处理，这就诞生了让算法在分布式环境中去执行，也就是让计算移动起来。

移动计算的大致过程是这样的：

- 在分布式集群里通过HDFS把数据文件管理起来
- 大数据引擎，比如Hadoop或Spark根据集群里不同服务器的计算能力来调度
- 应用程序打包
- Hadoop或Spark启动命令执行包
- Hadoop或Spark根据要处理数据的路径，根据数据量大小，将数据切分成若干片
- 将数据片分配给集群里某台服务器上的某个进程
- 进程检查是否有这个计算程序包，如果没有就去下载，之后通过反射加载到进程里的程序
- 进程程序根据文件地址和数据在文件中的偏移量进行计算

Hadoop和Spark就是这样的编程模型，不仅切分数据，还把算法分发到服务器集群里的进程里对切片数据进行处理。

