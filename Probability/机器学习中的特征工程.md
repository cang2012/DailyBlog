机器学习分为有监督学习Supervised Learning和无监督学习Unsupervised Learning。有监督机器学习通过样本建立一个模型，根据模型推断出新的实例，用到的方法包括分类Classification和回归Regression。

机器学习的过程通常包括：准备数据、特征工程、模型拟合、离线或在线测试。

特征工程中，包括特征的数据化，比如把水果的各类特征转换为计算机能理解的数据；还包括特征选择，是指发觉和预定义任务相关特征，过滤噪音的过程；还包括缺失值的弥补；还包括异常值的处理。

特征的产生、搜索、评估一种方式是穷举法，复杂度是O(2的N次方)，如果数据多这种方式就不适合了。

还有是通过信息熵进行特征选择。如果一个特征只在某个或少数几个分类中出现，而很少在其它分类中出现，那这个特征具有较强的区分力，也是对分类有价值的特征。比如在某篇文章中，电影属于娱乐这个分类，不属于军事或政治分类，电影这个词就是具有价值的特征。站在熵的角度，如果熵值低，说明这个特征的数据只出现在少数分类中。但是，如果把范围放到整个数据集中时，如果在整个数据集中娱乐这个分类已经占觉大多数，那电影就不是一个有价值的特征。这时候需要结合信息增益，信息增益越大，说明特征对于分类的价值越大。

还有一种方式是卡方检验。在统计学中，使用卡方来检验两个变量是否相互独立。在特征选择中，这种方式也可以拿来用，如果特征和分类有很强的独立性，特征对于分类就没有提供足够的信息量，对分类没有价值；反之就有价值。